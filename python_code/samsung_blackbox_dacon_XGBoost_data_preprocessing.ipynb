{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vsu0NOL18cwI",
        "outputId": "637cfb25-a8e3-4d5f-8751-80996894b42c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8PBxv3x8DwY",
        "outputId": "a177e259-4c15-4fa0-868e-405c5db1a453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 2187 candidates, totalling 6561 fits\n",
            "Best parameters found: {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 500, 'subsample': 0.7}\n",
            "Best cross-validation score: 1.7038\n",
            "Top 10% threshold: 85.8615\n",
            "Number of samples in top 10%: 504\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/samsung_blackbox_data/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/samsung_blackbox_data/test.csv')\n",
        "\n",
        "# \"버전 1\" 전처리: x_6 제거 및 이상치 제거\n",
        "def remove_outliers(df):\n",
        "    # 숫자형 피처만 선택\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "    Q1 = numeric_df.quantile(0.25)\n",
        "    Q3 = numeric_df.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    # 이상치를 제거하고, 원본 데이터프레임의 인덱스에 맞춰서 반환\n",
        "    df_out = df[~((numeric_df < (Q1 - 1.5 * IQR)) | (numeric_df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "    return df_out\n",
        "\n",
        "# 1. `x_6` 피처 제거\n",
        "train_df_v1 = train_df.drop(columns=['x_6'])\n",
        "test_df_v1 = test_df.drop(columns=['x_6'])\n",
        "\n",
        "# 2. 이상치 제거\n",
        "train_df_v1 = remove_outliers(train_df_v1)\n",
        "\n",
        "# Features and target\n",
        "X = train_df_v1.iloc[:, 1:-1]  # Features (x_0 to x_10 except x_6)\n",
        "y = train_df_v1.iloc[:, -1]  # Target (label)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the XGBoost model\n",
        "xgb_model = xgb.XGBRegressor(random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 300, 500],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.7, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid,\n",
        "                           cv=3, scoring='neg_mean_squared_error',\n",
        "                           verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and score\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {-grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Train the model with the best parameters on the full training data\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "X_test = test_df_v1.iloc[:, 1:]  # Test features\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Identify top 10% of predicted values\n",
        "threshold = np.percentile(y_pred, 90)\n",
        "top_10_percent_mask = y_pred >= threshold\n",
        "\n",
        "# Create submission file with ID and y columns (y = 1 for top 10%, 0 otherwise)\n",
        "submission_df = pd.DataFrame({\n",
        "    'ID': test_df_v1.iloc[:, 0],  # Assuming first column is ID in test.csv\n",
        "    'y': np.where(top_10_percent_mask, 1, 0)  # 1 for top 10%, 0 otherwise\n",
        "})\n",
        "\n",
        "# Save the submission file\n",
        "submission_df.to_csv('/content/drive/MyDrive/samsung_blackbox_data/xgboost_submission_after_data_preprocessing.csv', index=False)\n",
        "\n",
        "print(f\"Top 10% threshold: {threshold:.4f}\")\n",
        "print(f\"Number of samples in top 10%: {sum(top_10_percent_mask)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zjY1mrN632MW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}